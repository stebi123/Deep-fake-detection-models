# -*- coding: utf-8 -*-
"""ViT model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13Y3FOfgwe35upAiNAXC6rUKm_5eW6LHw
"""

# Import required libraries
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from transformers import ViTForImageClassification, ViTFeatureExtractor
from torch.utils.data import DataLoader
from PIL import Image

# Check if GPU is available and use it
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# 1. Define Paths for Your Datasets
# =================================
# Add your dataset paths below
train_data_dir = "/content/drive/MyDrive/dataset 50,250/train 1000"  # Replace with your train dataset path
val_data_dir = "/content/drive/MyDrive/dataset 50,250/validation 1000"  # Replace with your validation dataset path
test_data_dir = "/content/drive/MyDrive/dataset 50,250/test 50"    # Replace with your test dataset path

# 2. Data Preprocessing
# =================================
print("Initializing Vision Transformer feature extractor...")
feature_extractor = ViTFeatureExtractor.from_pretrained("google/vit-base-patch16-224-in21k")

# Custom transform for the ViT model
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std),
])

# Load datasets
print("Loading datasets...")
train_dataset = datasets.ImageFolder(root=train_data_dir, transform=transform)
val_dataset = datasets.ImageFolder(root=val_data_dir, transform=transform)
test_dataset = datasets.ImageFolder(root=test_data_dir, transform=transform)

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

print("Datasets loaded successfully!")

# 3. Define the Model: ViT
# =================================
print("Loading Vision Transformer model...")
model = ViTForImageClassification.from_pretrained(
    "google/vit-base-patch16-224-in21k",
    num_labels=2  # Binary classification: Real (0) or Fake (1)
)

# Move the model to GPU if available
model = model.to(device)

# Define Loss Function and Optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

# 4. Training Function
# =================================
def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5):
    for epoch in range(num_epochs):
        print(f"Epoch {epoch+1}/{num_epochs}")
        model.train()
        running_loss = 0.0
        correct, total = 0, 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward + Backward + Optimize
            outputs = model(inputs).logits  # ViT returns a dict with logits
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # Calculate accuracy
            _, preds = torch.max(outputs, 1)
            running_loss += loss.item()
            correct += (preds == labels).sum().item()
            total += labels.size(0)

        epoch_loss = running_loss / len(train_loader)
        epoch_acc = correct / total * 100
        print(f"Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_acc:.2f}%")

        # Validation Phase
        validate_model(model, val_loader, criterion)

# 5. Validation Function
# =================================
def validate_model(model, val_loader, criterion):
    model.eval()
    running_loss = 0.0
    correct, total = 0, 0

    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs).logits
            loss = criterion(outputs, labels)

            _, preds = torch.max(outputs, 1)
            running_loss += loss.item()
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    val_loss = running_loss / len(val_loader)
    val_acc = correct / total * 100
    print(f"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\n")

# 6. Train and Validate the Model
# =================================
num_epochs = 5  # Change number of epochs if needed
print("Starting training...")
train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)
print("Training completed!")

# 7. Testing and Predicting on New Images
# =================================
def predict(model, test_loader):
    model.eval()
    class_names = ["Real", "Fake"]

    print("\nTesting the model...")
    with torch.no_grad():
        for inputs, _ in test_loader:
            inputs = inputs.to(device)
            outputs = model(inputs).logits
            _, preds = torch.max(outputs, 1)
            print(f"Prediction: {class_names[preds[0]]}")

# Run prediction on the test set
predict(model, test_loader)

# Save the trained model
torch.save(model.state_dict(), "deepfake_vit_model.pth")
print("Model saved as 'deepfake_vit_model.pth'")

torch.save(model, "deepfake_ViTmodel_full_model.pth")

# Load a pre-trained ViT model for image classification
model = ViTForImageClassification.from_pretrained(
    "google/vit-base-patch16-224",  # Replace with your ViT variant
    num_labels=2,                   # Binary classification (Real: 0, Fake: 1)
    ignore_mismatched_sizes=True    # Ignore size mismatch for classifier layer
)

# Load the saved state dictionary
model.load_state_dict(torch.load("deepfake_vit_model.pth"))

# Set the model to evaluation mode for inference
model.eval()

"""Now test an input!!!!

"""

# Load and preprocess an image
image_path = "/content/drive/MyDrive/dataset 50,250/test 50/real/real_11.jpg"  # Replace with the path to your test image

# Open and preprocess the image
image = Image.open(image_path).convert("RGB")
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resize for ViT
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
input_tensor = transform(image).unsqueeze(0)  # Add batch dimension

# Perform inference
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
input_tensor = input_tensor.to(device)  # Move input to the same device as the model
model = model.to(device)  # Ensure the model is on the correct device

with torch.no_grad():
    output = model(input_tensor).logits  # Use `.logits` for Hugging Face ViT models

# Interpret the output
_, predicted_class = torch.max(output, 1)  # Get the index of the highest score
if predicted_class.item() == 0:
    print("The image is REAL.")
else:
    print("The image is FAKE.")

# Accuracy of the model
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# Ensure the model is in evaluation mode
model.eval()

# Initialize lists to store true labels and predictions
true_labels = []
predicted_labels = []

# Loop through the test DataLoader
with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        # Perform inference
        outputs = model(inputs).logits  # Use .logits for ViT models
        _, preds = torch.max(outputs, 1)

        # Store labels and predictions
        true_labels.extend(labels.cpu().numpy())
        predicted_labels.extend(preds.cpu().numpy())

# Convert lists to numpy arrays
true_labels = np.array(true_labels)
predicted_labels = np.array(predicted_labels)

# Compute and display classification metrics
print("Classification Report:")
print(classification_report(true_labels, predicted_labels, target_names=["Real", "Fake"]))

# Compute the confusion matrix
cm = confusion_matrix(true_labels, predicted_labels)

# Plot the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Real", "Fake"])
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()