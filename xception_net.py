# -*- coding: utf-8 -*-
"""Xception_net.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qfeK3UTpD4JTwJWfmdYPg_8z6zaMN7cT
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from PIL import Image
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np
from torchvision.models import inception_v3

# Check if GPU is available and use it
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# 1. Define Paths for Your Datasets
train_data_dir = "/content/drive/MyDrive/2000.1000.50 dataset/Train"
val_data_dir = "/content/drive/MyDrive/2000.1000.50 dataset/Validation"
test_data_dir = "/content/drive/MyDrive/2000.1000.50 dataset/Test"

from google.colab import drive
drive.mount('/content/drive')

# 2. Data Preprocessing with Augmentation
transform_train = transforms.Compose([
    transforms.Resize((299, 299)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

transform_val_test = transforms.Compose([
    transforms.Resize((299, 299)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Load datasets
print("Loading datasets...")
train_dataset = datasets.ImageFolder(root=train_data_dir, transform=transform_train)
val_dataset = datasets.ImageFolder(root=val_data_dir, transform=transform_val_test)
test_dataset = datasets.ImageFolder(root=test_data_dir, transform=transform_val_test)

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

print("Datasets loaded successfully!")

# 3. Define the Model
print("Loading InceptionV3 model...")
model = inception_v3(pretrained=True)

# Fine-tune by unfreezing layers
for param in model.parameters():
    param.requires_grad = True

# Modify the final layer for binary classification
model.fc = nn.Linear(model.fc.in_features, 2)

# Move the model to GPU if available
model = model.to(device)

# Weighted Loss Function
class_weights = torch.tensor([1.0, 2.0])  # Adjust based on class imbalance
criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))

# Optimizer and Scheduler
optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

# 4. Training Function with Early Stopping
def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20, patience=3):
    best_val_loss = float('inf')
    patience_counter = 0

    for epoch in range(num_epochs):
        print(f"Epoch {epoch+1}/{num_epochs}")
        model.train()
        running_loss, correct, total = 0.0, 0, 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            if isinstance(outputs, tuple):
                outputs = outputs[0]
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            _, preds = torch.max(outputs, 1)
            running_loss += loss.item()
            correct += (preds == labels).sum().item()
            total += labels.size(0)

        train_loss = running_loss / len(train_loader)
        train_acc = correct / total * 100
        val_loss, val_acc = validate_model(model, val_loader, criterion)

        print(f"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%")
        print(f"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%")

        # Check for early stopping
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            torch.save(model.state_dict(), "best_model.pth")
            print("Best model saved!")
        else:
            patience_counter += 1

        if patience_counter >= patience:
            print("Early stopping triggered!")
            break

        scheduler.step()

# 5. Validation Function
def validate_model(model, val_loader, criterion):
    model.eval()
    running_loss, correct, total = 0.0, 0, 0

    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            if isinstance(outputs, tuple):
                outputs = outputs[0]
            loss = criterion(outputs, labels)
            _, preds = torch.max(outputs, 1)
            running_loss += loss.item()
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    val_loss = running_loss / len(val_loader)
    val_acc = correct / total * 100
    return val_loss, val_acc

# 6. Train and Validate the Model
print("Starting training...")
train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20, patience=3)
print("Training completed!")

# 7. Testing and Predicting on New Images
def predict(model, test_loader):
    model.eval()
    class_names = ["Real", "Fake"]
    predictions = []

    print("\nTesting the model...")
    with torch.no_grad():
        for inputs, _ in test_loader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            if isinstance(outputs, tuple):
                outputs = outputs[0]
            _, preds = torch.max(outputs, 1)
            predictions.append(preds.item())
            print(f"Prediction: {class_names[preds.item()]}")

    return predictions

# Run prediction on the test set
model.load_state_dict(torch.load("best_model.pth"))
predictions = predict(model, test_loader)

# Accuracy of the model
model.eval()
true_labels = []
predicted_labels = []

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        if isinstance(outputs, tuple):
            outputs = outputs[0]
        _, preds = torch.max(outputs, 1)
        true_labels.extend(labels.cpu().numpy())
        predicted_labels.extend(preds.cpu().numpy())

true_labels = np.array(true_labels)
predicted_labels = np.array(predicted_labels)

print("Classification Report:")
print(classification_report(true_labels, predicted_labels, target_names=["Real", "Fake"]))

cm = confusion_matrix(true_labels, predicted_labels)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Real", "Fake"])
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

torch.save(model.state_dict(), "inception_v3_model.pth")