# -*- coding: utf-8 -*-
"""CNN (vgg19).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/183t07nD2k2Fl0GB7ulNmZS3WWTPoImkY
"""

# Import required libraries
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
from PIL import Image
# Check if GPU is available and use it
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")
# 1. Define Paths for Your Datasets
# =================================
# Add your dataset paths below
train_data_dir = '/content/drive/MyDrive/6k_800_800/Train'
val_data_dir = '/content/drive/MyDrive/6k_800_800/Valiadation'
test_data_dir = '/content/drive/MyDrive/6k_800_800/Test'

from google.colab import drive
drive.mount('/content/drive')

# 2. Data Preprocessing
# =================================
transform = transforms.Compose([
    transforms.Resize((224, 224)),   # Resize images for VGG19
    transforms.ToTensor(),           # Convert images to PyTorch tensors
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for VGG19
])

# Load datasets
print("Loading datasets...")
train_dataset = datasets.ImageFolder(root=train_data_dir, transform=transform)
val_dataset = datasets.ImageFolder(root=val_data_dir, transform=transform)
test_dataset = datasets.ImageFolder(root=test_data_dir, transform=transform)

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

print("Datasets loaded successfully!")

# 3. Define the Model: VGG19
# =================================
print("Loading VGG19 model...")
model = models.vgg19(pretrained=True)

# Modify the final layer to match binary classification (Real: 0, Fake: 1)
model.classifier[6] = nn.Linear(4096, 2)

# Move the model to GPU if available
model = model.to(device)

# Define Loss Function and Optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

# 4. Training Function
# =================================
def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5):
    for epoch in range(num_epochs):
        print(f"Epoch {epoch+1}/{num_epochs}")
        model.train()
        running_loss = 0.0
        correct, total = 0, 0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward + Backward + Optimize
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # Calculate accuracy
            _, preds = torch.max(outputs, 1)
            running_loss += loss.item()
            correct += (preds == labels).sum().item()
            total += labels.size(0)

        epoch_loss = running_loss / len(train_loader)
        epoch_acc = correct / total * 100
        print(f"Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_acc:.2f}%")

        # Validation Phase
        validate_model(model, val_loader, criterion)

        # 5. Validation Function
# =================================
def validate_model(model, val_loader, criterion):
    model.eval()
    running_loss = 0.0
    correct, total = 0, 0

    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            _, preds = torch.max(outputs, 1)
            running_loss += loss.item()
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    val_loss = running_loss / len(val_loader)
    val_acc = correct / total * 100
    print(f"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\n")

# 6. Train and Validate the Model with Early Stopping
# ====================================================
class EarlyStopping:
    """Class to implement early stopping."""
    def __init__(self, patience=5, delta=0.001):
        """
        Args:
            patience (int): How many epochs to wait after last improvement.
            delta (float): Minimum change to qualify as an improvement.
        """
        self.patience = patience
        self.delta = delta
        self.best_loss = float('inf')
        self.counter = 0
        self.early_stop = False

    def __call__(self, val_loss):
        if val_loss < self.best_loss - self.delta:
            self.best_loss = val_loss
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True

# Initialize early stopping
patience = 3  # Adjust patience as needed
early_stopping = EarlyStopping(patience=patience)

num_epochs = 20  # Set a higher number of epochs to allow early stopping to kick in
print("Starting training...")

for epoch in range(num_epochs):
    print(f"Epoch {epoch + 1}/{num_epochs}")

    # Training step
    model.train()
    train_loss = 0.0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
    train_loss /= len(train_loader)

    # Validation step
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
    val_loss /= len(val_loader)

    print(f"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")

    # Early stopping check
    early_stopping(val_loss)
    if early_stopping.early_stop:
        print(f"Early stopping triggered at epoch {epoch + 1}.")
        break

print("Training completed!")

# Save the trained model
torch.save(model.state_dict(), "vgg19_new_dataset_model.pth")
print("Model saved as 'deepfake_vgg19_model.pth'")

# 7. Testing and Predicting on New Images
# ========================================
def predict(model, test_loader):
    model.eval()
    class_names = ["Real", "Fake"]

    print("\nTesting the model...")
    with torch.no_grad():
        for inputs, _ in test_loader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            print(f"Prediction: {class_names[preds[0]]}")

# Load the saved model before testing (to ensure continuity)
print("\nLoading the saved model for testing...")
model.load_state_dict(torch.load("vgg19_new_dataset_model.pth"))
model.to(device)

# Run prediction on the test set
predict(model, test_loader)

# Initialize the same model architecture
model = models.vgg19(pretrained=True)
model.classifier[-1] = nn.Linear(4096, 2)  # Modify the output layer for binary classification

# Load the saved state dictionary
model.load_state_dict(torch.load("vgg19_new_dataset_model.pth"))

# Set the model to evaluation mode for inference
model.eval()

# Accuracy of the model
import torch
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

model = model.to(device)

# Ensure the model is in evaluation mode
model.eval()

# Initialize lists to store true labels and predictions
true_labels = []
predicted_labels = []

# Loop through the test DataLoader
with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        # Perform inference
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)

        # Store labels and predictions
        true_labels.extend(labels.cpu().numpy())
        predicted_labels.extend(preds.cpu().numpy())

# Convert lists to numpy arrays
true_labels = np.array(true_labels)
predicted_labels = np.array(predicted_labels)

# Compute and display classification metrics
print("Classification Report:")
print(classification_report(true_labels, predicted_labels, target_names=["Real", "Fake"]))

# Compute the confusion matrix
cm = confusion_matrix(true_labels, predicted_labels)

# Plot the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Real", "Fake"])
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()
